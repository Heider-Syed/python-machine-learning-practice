{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Breast cancer wisconcin dataset\n",
    "The goal of the dataset is to predict if the patient has cancer (benign or malignant) based on their characteristics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malignant: causes cancer and is dangerous, meaning it can grow and spread to other parts of the body.\n",
    "\n",
    "Benign: it is not cancer, they only grow in one part of the body. They cannot appear or invade other parts of the body."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T # display the describe with a transpose that allows you to see all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of null/missing values in each column of the (wisconcin cancer dataset)\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diagnosis.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaner(data):\n",
    "    data.drop(\"Unnamed: 32\", axis=1, inplace=True)\n",
    "    data.drop(\"id\", axis=1, inplace=True)\n",
    "    \n",
    "    # Since the model will not understand what (M,B) means, I will transform it into numerical values that represent them\n",
    "    data[\"diagnosis\"] = data[\"diagnosis\"].map({\"M\":1, \"B\":0})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCleaner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diagnosis\"].value_counts() # malignant:1 , benign:0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= sns.countplot(x=\"diagnosis\", data= df)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Number of diagnosis per type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr, cmap=\"RdBu\", vmin=-1, vmax=1, annot=True)\n",
    "plt.title(\"Correlation heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a matrix as a scatterplot with the columns \"mean: _mean\"\n",
    "# create a list with the columns to graph\n",
    "cols= [\"diagnosis\",\n",
    "            \"radius_mean\",\n",
    "            \"texture_mean\",\n",
    "            \"perimeter_mean\",\n",
    "            \"area_mean\",\n",
    "            \"smoothness_mean\",\n",
    "            \"compactness_mean\",\n",
    "            \"concavity_mean\",\n",
    "            \"concave points_mean\",\n",
    "            \"symmetry_mean\",\n",
    "            \"fractal_dimension_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a pairplot with each of the cols that has a hue in the diagnosis to see the\n",
    "# correlation between each of the columns with the diagnosis\n",
    "sns.pairplot(data=df[cols], hue=\"diagnosis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that there are nearly perfect linear patterns between radius, perimeter, and area.\n",
    "\n",
    "these attributes give a clue that there is multicollinearity between these variables. (These are highly linearly related), another set of variables that possibly imply/show multicollinearity are: concavity, concave_points and compactness.\n",
    "\n",
    "multicollinearity is a problem since it is a statistical concept in which several independent variables are correlated in a model. Two variables are considered to be perfectly collinear if their correlation coefficient is +/- 1.0. Multicollinearity between independent variables will result in less reliable statistical inferences.\n",
    "\n",
    "We can solve this by removing the highly correlated predictors from the model, we can use Partial Least Squares Regression (PLS) or Principal Components Analysis, these are regression methods that cut the number of predictors to a smaller set of uncorrelated components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the correlation matrix to understand this case\n",
    "corr = corr.round(2) # round to 2 decimal places\n",
    "\n",
    "# Mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# define the size of the figure\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "# draw the heatmap\n",
    "sns.heatmap(corr, mask=mask, cmap=\"RdBu\", vmin=-1, vmax= 1, center= 0,\n",
    "            square=True, linewidth= .5, cbar_kws={\"shrink\":.5}, annot=True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can verify the presence of multicollinearity between some of the variables.\n",
    "\n",
    "for example, the radius_mean column has a correlation of 1 and 0.99 with the perimeter_mean and area_mean columns, respectively.\n",
    "\n",
    "This is because the 3 columns contain essentially the same information, which is the physical size of the observation (the cell).\n",
    "\n",
    "therefore we should choose (1) of these 3 columns when we are going to perform future analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another place where multicollinearity is apparent is between the \"mean\" and \"worst\" columns, for example, the radius_mean column has a correlation of 0.97 with the radius_worst column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also multicollinearity between the compactness, concavity and concave points attributes. therefore we can choose(1) from those columns.\n",
    "\n",
    "I will choose compactness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. we drop all the worst columns\n",
    "cols = [\"radius_worst\",\n",
    "            \"texture_worst\",\n",
    "            \"perimeter_worst\",\n",
    "            \"area_worst\",\n",
    "            \"smoothness_worst\",\n",
    "            \"compactness_worst\",\n",
    "            \"concavity_worst\",\n",
    "            \"concave points_worst\",\n",
    "            \"symmetry_worst\",\n",
    "            \"fractal_dimension_worst\"]\n",
    "\n",
    "df = df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. dropeamos todas las columnas relacionadas a los atributos de \"perimeter\" y \"area\"\n",
    "cols = [\"perimeter_mean\", \"perimeter_se\", \"area_mean\", \"area_se\"]\n",
    "\n",
    "df= df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. and last we drop all the columns related to the attributes of \"concavity\" and \"concave points\"\n",
    "cols = [\"concavity_mean\", \"concavity_se\", \"concave points_mean\", \"concave points_se\"]\n",
    "\n",
    "df = df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check that the changes have taken effect and we keep the important columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a heatmap again, with the new correlation matrix to see if there is any high correlation left\n",
    "corr = df.corr().round(2)\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=\"RdBu\", vmin=-1, vmax= 1, center= 0,\n",
    "            square=True, linewidth= .5, cbar_kws={\"shrink\":.5}, annot=True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this we have removed the multicollinearity and we can now create the machine learning model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"diagnosis\", axis=1)\n",
    "y = df[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler() # make all values have a certain standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Finding the best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "model1 = lr.fit(X_train, y_train)\n",
    "prediction1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction1)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1Accuracy = accuracy_score(y_test, prediction1)\n",
    "print(f\"The logistic regression model an accuracy of: {model1Accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report of logistic regression: \\n\", classification_report(y_test, prediction1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = dtc.fit(X_train, y_train)\n",
    "prediction2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test, prediction2)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2Accuracy = accuracy_score(y_test, prediction2)\n",
    "print(f\"The decision tree classifier model an accuracy of: {model2Accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report of decision tree classifer : \\n\", classification_report(y_test, prediction2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = rfc.fit(X_train, y_train)\n",
    "prediction3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(y_test, prediction3)\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm3, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3Accuracy = accuracy_score(y_test, prediction3)\n",
    "print(f\"The random forest model an accuracy of: {model3Accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report of random forest : \\n\", classification_report(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the model to use it whenever we want without having to train it more\n",
    "# dump(model1, \"Logistic-regression-model.joblib\") # save the model and give the file a name along with the extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel = load(\"Logistic-regression-model.joblib\") # load the model that we had already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the model that we trained with data that we invented based on the columns\n",
    "pred = trainedModel.predict([[22, 10, 0.1190, 0.3, 0.1855, 0.7790, 0.7723, 0.8669, 0.09776, 0.5932, 0.30015, 0.006193]])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred == 1:\n",
    "    print(\"The patient has malignant cancer\")\n",
    "else:\n",
    "    print(\"The patient has benign cancer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b63bb9ef0b26197c9886b05626e449261673d5c160f3a37dbcf82eb7a2f587ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
